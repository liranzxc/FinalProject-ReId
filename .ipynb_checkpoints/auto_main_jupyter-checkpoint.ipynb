{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pip install opencv-contrib-python==3.4.2.16\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "import cv2\n",
    "from finalProject.classes.yolo import Yolo\n",
    "from finalProject.utils.drawing.draw import drawTargetFinal\n",
    "from finalProject.utils.images.imagesUtils import Image\n",
    "from finalProject.utils.keyPoints.AlgoritamKeyPoints import createDescriptorTarget, SiftDetectKeyPoints\n",
    "from finalProject.utils.matchers.Matchers import compare_between_two_description, flannmatcher\n",
    "from finalProject.utils.preprocessing.preprocess import readFromInputVideoFrames, framesExists, reduceNoise, \\\n",
    "    removeRemovalColor\n",
    "from finalProject.utils.tracking.TrackingByYolo import source_detection_by_yolo, tracking_by_yolo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sobel(img):\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    sobel_intensity = cv2.sqrt(cv2.addWeighted(cv2.pow(sobelx, 2.0),\n",
    "                                               1.0, cv2.pow(sobely, 2.0), 1.0, 0.0))\n",
    "    return sobel_intensity\n",
    "\n",
    "\n",
    "def sobel_keypoints(image):\n",
    "    sobelImage = sobel(image)\n",
    "    # norm\n",
    "    image8bit = cv2.normalize(sobelImage, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    k, d = SiftDetectKeyPoints(image8bit)\n",
    "    return k, d, image8bit\n",
    "\n",
    "\n",
    "def forward(frames):\n",
    "    outputs = []\n",
    "    for frame in frames:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = sobel(frame)\n",
    "        key_des_image = sobel_keypoints(frame)\n",
    "        outputs.append(key_des_image)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def cross_correction(key_des_image_source, key_des_image_target, threshold=0.5):\n",
    "    (k1, d1, img1) = key_des_image_source\n",
    "    (k2, d2, img2) = key_des_image_target\n",
    "    match = flannmatcher(d1, d2, threshold=threshold)\n",
    "    output = cv2.drawMatchesKnn(img1, k1, img2, k2, match, outImg=None)\n",
    "    return output\n",
    "\n",
    "\n",
    "def plotSquare(images, _titles, each_column=5):\n",
    "    number_images = len(images)  # 10\n",
    "    rows = (number_images // each_column) \n",
    "    index = 1\n",
    "\n",
    "    print(rows)\n",
    "    fig, axes = plt.subplots(rows, each_column, figsize=(48, 24),dpi=80)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.05)\n",
    "    \n",
    "    for ax,image,title in zip(axes.flat,images,_titles):\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(title)\n",
    "        index += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading YOLO from disk...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# init yolo\n",
    "yolo = Yolo()\n",
    "yolo.initYolo()\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "with open('./config.txt') as file_json:\n",
    "    config = json.load(file_json)\n",
    "\n",
    "    # source\n",
    "    frameSource = readFromInputVideoFrames(config[\"source\"])\n",
    "    if not framesExists(frameSource):\n",
    "        print(\"problem with source video input\")\n",
    "        exit(0)\n",
    "\n",
    "    mySource = source_detection_by_yolo(frameSource, yolo,\n",
    "                                        isVideo=config[\"source\"][\"isVideo\"],\n",
    "                                        config=config[\"source\"])\n",
    "    if mySource is None:\n",
    "        print(\"fail to detect human on source video\")\n",
    "        exit(0)\n",
    "\n",
    "    # target\n",
    "    frameTarget = readFromInputVideoFrames(config[\"target\"])\n",
    "    if not framesExists(frameTarget):\n",
    "        print(\"problem with target video input\")\n",
    "        exit(0)\n",
    "\n",
    "    if not framesExists(frameTarget):\n",
    "        print(\"problem with target video input -reduce noise\")\n",
    "        exit(0)\n",
    "\n",
    "    myTargets = tracking_by_yolo(frameTarget, yolo, isVideo=config[\"target\"][\"isVideo\"],\n",
    "                                 config=config[\"target\"])\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    # source\n",
    "\n",
    "    sources_output = forward(mySource.frames)  # array of outputs (key,des,image)\n",
    "    targets_outputs = []  # array of targets , each target have array of frames\n",
    "    for target in myTargets:\n",
    "        target_output = forward(target.frames)  # array of frames\n",
    "        targets_outputs.append(target_output)\n",
    "\n",
    "    plots = []  # each frame\n",
    "\n",
    "    for source_frame in sources_output:\n",
    "        for target in targets_outputs:\n",
    "            for target_frame in target:\n",
    "                plots.append(cross_correction(source_frame, target_frame))\n",
    "\n",
    "\n",
    "    titles = [\"test\"] * (len(plots) - 1)\n",
    "    plotSquare(plots, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
